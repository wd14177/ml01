{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e4e1a27",
   "metadata": {},
   "source": [
    "# 📔 [강의 자료] Scikit-learn을 활용한 데이터 전처리\n",
    "\n",
    "## 1. 개요 (Introduction)\n",
    "머신러닝 프로젝트에서 데이터 전처리는 모델의 성능을 결정짓는 핵심 단계입니다. **사이킷런(Scikit-learn)**은 이를 위해 통일된 인터페이스를 제공합니다.\n",
    "\n",
    "### 🛠️ 핵심 메서드 (The Big Three)\n",
    "사이킷런의 모든 전처리 객체는 다음 세 가지 메서드를 공통으로 사용합니다.\n",
    "\n",
    "1. **`fit()`**: 데이터로부터 변환에 필요한 통계량(평균, 표준편차 등)을 학습합니다.\n",
    "2. **`transform()`**: 학습된 기준을 바탕으로 실제 데이터를 변환합니다.\n",
    "3. **`fit_transform()`**: 학습과 변환을 한 번에 수행합니다. (훈련 데이터용)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. 데이터 스케일링 (Data Scaling)\n",
    "수치형 데이터들의 단위(Scale)가 다를 때 이를 일정하게 맞추는 작업입니다.\n",
    "\n",
    "### 🔹 StandardScaler (표준화)\n",
    "* **특징**: 데이터를 평균 0, 분산 1인 정규분포 형태로 만듭니다.\n",
    "* **용도**: 대부분의 머신러닝 알고리즘(회귀, SVM 등)에서 기본적으로 사용됩니다.\n",
    "\n",
    "\n",
    "### 🔹 MinMaxScaler (정규화)\n",
    "* **특징**: 데이터를 0과 1 사이의 값으로 변환합니다.\n",
    "* **용도**: 데이터의 최소/최대 범위를 명확히 알 때(예: 이미지 픽셀) 주로 사용합니다.\n",
    "\n",
    "### 🔹 RobustScaler\n",
    "* **특징**: 중앙값과 사분위수(IQR)를 사용하여 계산합니다.\n",
    "* **장점**: **이상치(Outlier)**의 영향이 큰 데이터셋에서 효과적입니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. 결측치 및 범주형 데이터 처리\n",
    "\n",
    "### 📁 SimpleImputer (결측치 처리)\n",
    "데이터 세트에 누락된 값(NaN)이 있을 때 이를 채워줍니다.\n",
    "* **평균(mean) / 중앙값(median)**: 수치형 데이터 보간.\n",
    "* **최빈값(most_frequent)**: 범주형 데이터 보간.\n",
    "\n",
    "### 🏷️ 인코딩 (Categorical Encoding)\n",
    "텍스트로 된 범주형 데이터를 숫자로 변환하는 과정입니다.\n",
    "\n",
    "| 클래스 명 | 설명 | 주요 사용처 |\n",
    "| :--- | :--- | :--- |\n",
    "| **LabelEncoder** | 카테고리를 숫자(0, 1, 2...)로 변환 | 타겟 변수(정답), 트리 모델 |\n",
    "| **OneHotEncoder** | 각 범주를 별도의 열로 분리 (0/1 표시) | 선형 모델, 신경망 |\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 4. 실무 주의사항: 데이터 누수 (Data Leakage)\n",
    "전처리 과정에서 가장 주의해야 할 점은 **훈련 데이터의 기준을 테스트 데이터에 적용**해야 한다는 것입니다.\n",
    "\n",
    "* **훈련 데이터(Train Set)**: `fit_transform()` 사용 가능.\n",
    "* **테스트 데이터(Test Set)**: **반드시** 훈련 데이터로 만든 객체를 활용해 `transform()`만 수행.\n",
    "  - *이유: 테스트 데이터의 평균이나 최대치를 학습 과정에 반영하는 것은 일종의 '커닝'이기 때문입니다.*\n",
    "\n",
    "---\n",
    "\n",
    "## 5. 요약: 상황별 전처리 도구 선택\n",
    "\n",
    "| 상황 | 추천 도구 |\n",
    "| :--- | :--- |\n",
    "| 변수들의 단위가 제각각일 때 | `StandardScaler` |\n",
    "| 데이터가 0~1 사이에 있어야 할 때 | `MinMaxScaler` |\n",
    "| 이상치(튀는 값)가 너무 많을 때 | `RobustScaler` |\n",
    "| 데이터에 빈 칸(NaN)이 있을 때 | `SimpleImputer` |\n",
    "| 카테고리형 데이터를 숫자로 바꿀 때 | `OneHotEncoder` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210bed77",
   "metadata": {},
   "source": [
    "### 🏷️ LabelEncoder: 범주형 데이터 숫자로 바꾸기\n",
    "\n",
    "`LabelEncoder`는 문자로 된 카테고리 데이터를 단순한 **숫자 번호**로 바꾸는 가장 기본적인 도구입니다.\n",
    "\n",
    "### 핵심 요약\n",
    "* **역할**: 범주형(문자) 데이터를 정수(0, 1, 2, ...)로 변환합니다.\n",
    "* **순서**: 가나다 또는 알파벳 순서대로 0번부터 번호를 매깁니다.\n",
    "* **용도**: 주로 모델이 맞춰야 하는 **정답(Target) 변수**를 변환할 때 사용합니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b6b4134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 변환값: [0 1 3 4 2 1 0]\n",
      "인코딩 클래스(순서): ['TV' '냉장고' '선풍기' '전자레인지' '컴퓨터']\n",
      "숫자 [4, 0, 2]의 원본값: ['컴퓨터' 'TV' '선풍기']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. 데이터 준비\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '냉장고', 'TV']\n",
    "\n",
    "# 2. LabelEncoder 객체 생성 및 학습/변환\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(items)\n",
    "\n",
    "# 3. 결과 확인\n",
    "print(f\"인코딩 변환값: {labels}\")\n",
    "print(f\"인코딩 클래스(순서): {encoder.classes_}\")\n",
    "\n",
    "# 4. 역변환 (숫자를 다시 문자로)\n",
    "decoded = encoder.inverse_transform([4, 0, 2])\n",
    "print(f\"숫자 [4, 0, 2]의 원본값: {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4869873",
   "metadata": {},
   "source": [
    "### ⚖️ 피처 스케일링: 표준화 (Standardization)\n",
    "\n",
    "**표준화**는 데이터의 평균을 0, 표준편차를 1로 변환하여 데이터를 **표준 정규 분포**의 형태로 만드는 과정입니다.\n",
    "\n",
    "### 1. 핵심 요약\n",
    "* **역할**: 데이터가 평균으로부터 얼마나 떨어져 있는지(표준편차의 몇 배만큼)를 나타내는 수치로 변환합니다.\n",
    "* **공식**: $$z = \\frac{x - \\mu}{\\sigma}$$ (단, $\\mu$는 평균, $\\sigma$는 표준편차)\n",
    "* **특징**: 정규화(Min-Max)와 달리 데이터의 범위가 제한되지 않으며, 마이너스(-) 값이 발생할 수 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "### 💡 피처 스케일링의 작동 방식: \"열(Column) 단위 계산\"\n",
    "\n",
    "데이터 프레임에 여러 개의 열이 있을 때, 스케일러는 전체 데이터를 하나로 뭉쳐서 계산하지 않고 **각 열을 독립적인 단위**로 취급합니다.\n",
    "\n",
    "* **독립적 계산**: `Age` 열은 `Age`끼리, `Salary` 열은 `Salary`끼리 각각의 평균과 표준편차를 구합니다.\n",
    "* **이유**: 각 열마다 측정 단위(Unit)가 다르기 때문입니다. (세월 vs 화폐 단위)\n",
    "* **결과**: 변환이 끝나면 모든 열은 각자의 분포 안에서 평균 0, 표준편차 1(표준화 시)이라는 **공통된 기준점**을 갖게 되어 모델이 공정하게 학습할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5de21a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 원본 데이터 ---\n",
      "   Age  Salary\n",
      "0   25    2500\n",
      "1   35    4800\n",
      "2   45    7100\n",
      "3   50    5200\n",
      "\n",
      "--- 표준화 후 데이터 (평균 0, 표준편차 1) ---\n",
      "    Age  Salary\n",
      "0 -1.43   -1.47\n",
      "1 -0.39   -0.06\n",
      "2  0.65    1.35\n",
      "3  1.17    0.18\n",
      "\n",
      "--- 변환 후 평균값 (거의 0) ---\n",
      "Age       0.0\n",
      "Salary    0.0\n",
      "dtype: float64\n",
      "\n",
      "--- 변환 후 표준편차 (거의 1) ---\n",
      "Age       1.15\n",
      "Salary    1.15\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. 데이터 준비 (예: 나이와 연봉)\n",
    "data = {\n",
    "    'Age': [25, 35, 45, 50],\n",
    "    'Salary': [2500, 4800, 7100, 5200]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. StandardScaler 객체 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 3. 데이터 학습 및 변환 (fit + transform)\n",
    "# fit: 평균과 표준편차를 계산 / transform: 실제 값 변환\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "# 4. 결과 확인 (소수점 둘째자리까지)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "\n",
    "print(\"--- 원본 데이터 ---\")\n",
    "print(df)\n",
    "print(\"\\n--- 표준화 후 데이터 (평균 0, 표준편차 1) ---\")\n",
    "print(scaled_df.round(2))\n",
    "\n",
    "# 5. 통계치 확인\n",
    "print(\"\\n--- 변환 후 평균값 (거의 0) ---\")\n",
    "print(scaled_df.mean().round(2))\n",
    "print(\"\\n--- 변환 후 표준편차 (거의 1) ---\")\n",
    "print(scaled_df.std().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d7ade",
   "metadata": {},
   "source": [
    "# 📏 피처 스케일링: 정규화 (Min-Max Scaling)\n",
    "\n",
    "**정규화**는 서로 다른 범위의 숫자 데이터를 **0과 1 사이의 일정한 범위**로 압축하는 과정입니다.\n",
    "\n",
    "### 1. 핵심 요약\n",
    "* **역할**: 데이터의 최솟값을 0, 최댓값을 1로 변환하여 모든 데이터를 이 범위 안에 맞춥니다.\n",
    "* **공식**: $$x_{scaled} = \\frac{x - x_{min}}{x_{max} - x_{min}}$$\n",
    "* **특징**: 데이터의 상대적인 위치는 유지하면서 크기만 줄입니다. 모든 열(Feature)이 동일한 최소/최대 범위를 갖게 됩니다.\n",
    "\n",
    "[Image of Min-Max scaling formula and data points mapped from original scale to 0-1 range]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff37089a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 원본 데이터 ---\n",
      "   Score  Salary\n",
      "0     95    4500\n",
      "1     80    3000\n",
      "2     70    2800\n",
      "3    100    5000\n",
      "\n",
      "--- 정규화 후 데이터 (0~1 범위) ---\n",
      "      Score    Salary\n",
      "0  0.833333  0.772727\n",
      "1  0.333333  0.090909\n",
      "2  0.000000  0.000000\n",
      "3  1.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. 데이터 준비 (각 열의 범위가 아주 다른 경우)\n",
    "# 점수: 0~100점 / 연봉: 수천만 원 단위\n",
    "data = {\n",
    "    'Score': [95, 80, 70, 100],\n",
    "    'Salary': [4500, 3000, 2800, 5000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. MinMaxScaler 객체 생성\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 3. 데이터 학습 및 변환 (각 열별로 최솟값 0, 최댓값 1 설정)\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "# 4. 결과 확인\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "\n",
    "print(\"--- 원본 데이터 ---\")\n",
    "print(df)\n",
    "print(\"\\n--- 정규화 후 데이터 (0~1 범위) ---\")\n",
    "print(scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1610f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wanted3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
